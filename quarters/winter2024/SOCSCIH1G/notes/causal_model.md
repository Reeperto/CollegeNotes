# Problems with the DN Model

There were two major counterexamples to the DN model's explanatory power

1. Flagpole shadow => Over inclusion
    - The direction of explanation is sometimes not captured
2. John Jones Birth Control => Irrelevant inclusion

These problems were solved by introducing causal information to each explanation

1. The shadow does not cause the height of the flagpole
2. Birth control pills don't cause J.J. to be pregnant

The general issue with both is that the explanations cite information that aren't causes. One may ask why Hempel didn't include on causal information to avoid these issues? The answer: Hempel sees causal explanation as isomorphic to a DN explanation.

> Causation is a law of nature that needs to be specified

These counterexamples reveal that Hempel and the DN model are stuck.

# Causation

Causation has been seen as mysterious, problematic, and unclear by many scientists, philosophers, etc mostly in the late 19th and 20th centuries.

Russel's *On the notion of cause* offed an argument of the "complete" extrusion of cause from "advanced science" since none seek for causes.

## What is Causation?

> Causes explain their effects; Explaining an effect involves citing its main cause(s)

There are some motivating examples behind causation

- Increasing supply of money causes inflation
- Increasing prices of products causes demand to decrease
- Limited health insurance in certain groups causes their diminished health outcomes
- Passing a law on seatbelts causes a reduction in fatal car crashes 
- Lack of dietary vitamin C causes scurvy

Effects aren't necessarily products of a single cause. For example, a reduction in fatal car crashes could be an effect of both seatbelt laws and speed limits.

The challenge: **Once an effect/outcome is chosen, how do you identify which factors are and are not causes of it**

Why is it correct to say the flagpole's height causes the shadow but not the shadow causes the flagpole's height

## Interventionist Account (Woodward)

The interventionist account is the current mainstream explanation of causality and causal explanation. It has three main features

1. Counterfactuals
2. Intervention
3. Control

### Motivation

> I suggest below that the distinguishing feature of causal explanations, so conceived, is that they are explanations that furnish information that is potentially relevant to manipulation and control: they tell us how, if we were able to change the value of one or more variables, we could change the value of other variables (Woodward)

Therefore according to Woodward, we should care about causal explanations since they give us *control*. 

### Identifying Causes and Causal Explanation

The interventionist account identifies causes in the following manner:
$$
    \boxed{\text{X is a cause of Y} \Longleftrightarrow \text{Intervention of X produces changes in Y}}
$$
More succinctly, X provides control over Y. A requirement for causes is they must also have an associated "hypothetical" experiment: if X is manipulated, how would that change Y? Consider the following explanation

> If Venus had not entered your 11th house of friendship, this wouldn't have caused your desire to find pleasure through social contacts

This "causal" explanation fails to be a causal explanation because there is no hypothetical experiment we can perform. What would even mean to prevent Venus from entering "your 11th house of friendship"?

How can we make causal claims that refer to factors that we cannot control. For example

- Large scale cosmological events
    - Location of the moon and the changing tides
- Past Events
    - Yesterday I drank too much coffee and today have a headache
    - Large asteroid hitting the earth causing the extinction of the dinosaurs

Woodward handles these situations through counterfactuals: if (perhaps contrary to fact) the manipulation of the factors are possible, then there is a way to alter the phenomena in question.

That is, one must be able to associate with any successful explanation a **hypothetical or counterfactual experiment**.
