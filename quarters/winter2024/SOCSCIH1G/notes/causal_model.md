# Problems with the DN Model

There were two major counterexamples to the DN model's explanatory power

1. Flagpole shadow => Over inclusion
    - The direction of explanation is sometimes not captured
2. John Jones Birth Control => Irrelevant inclusion

These problems were solved by introducing causal information to each explanation

1. The shadow does not cause the height of the flagpole
2. Birth control pills don't cause J.J. to be pregnant

The general issue with both is that the explanations cite information that aren't causes. One may ask why Hempel didn't include on causal information to avoid these issues? The answer: Hempel sees causal explanation as isomorphic to a DN explanation.

> Causation is a law of nature that needs to be specified

These counterexamples reveal that Hempel and the DN model are stuck.

# Causation

Causation has been seen as mysterious, problematic, and unclear by many scientists, philosophers, etc mostly in the late 19th and 20th centuries.

Russel's *On the notion of cause* offed an argument of the "complete" extrusion of cause from "advanced science" since none seek for causes.

## What is Causation?

> Causes explain their effects; Explaining an effect involves citing its main cause(s)

There are some motivating examples behind causation

- Increasing supply of money causes inflation
- Increasing prices of products causes demand to decrease
- Limited health insurance in certain groups causes their diminished health outcomes
- Passing a law on seatbelts causes a reduction in fatal car crashes 
- Lack of dietary vitamin C causes scurvy

Effects aren't necessarily products of a single cause. For example, a reduction in fatal car crashes could be an effect of both seatbelt laws and speed limits.

The challenge: **Once an effect/outcome is chosen, how do you identify which factors are and are not causes of it**

Why is it correct to say the flagpole's height causes the shadow but not the shadow causes the flagpole's height

## Interventionist Account (Woodward)

The interventionist account is the current mainstream explanation of causality and causal explanation. It has three main features

1. Counterfactuals
2. Intervention
3. Control

### Motivation

> I suggest below that the distinguishing feature of causal explanations, so conceived, is that they are explanations that furnish information that is potentially relevant to manipulation and control: they tell us how, if we were able to change the value of one or more variables, we could change the value of other variables (Woodward)

Therefore according to Woodward, we should care about causal explanations since they give us *control*. 

### Identifying Causes and Causal Explanation

The interventionist account identifies causes in the following manner:
$$
    \boxed{\text{X is a cause of Y} \Longleftrightarrow \text{Intervention of X produces changes in Y}}
$$
More succinctly, X provides control over Y. A requirement for causes is they must also have an associated "hypothetical" experiment: if X is manipulated, how would that change Y? Consider the following explanation

> If Venus had not entered your 11th house of friendship, this wouldn't have caused your desire to find pleasure through social contacts

This "causal" explanation fails to be a causal explanation because there is no hypothetical experiment we can perform. What would even mean to prevent Venus from entering "your 11th house of friendship"?

How can we make causal claims that refer to factors that we cannot control. For example

- Large scale cosmological events
    - Location of the moon and the changing tides
- Past Events
    - Yesterday I drank too much coffee and today have a headache
    - Large asteroid hitting the earth causing the extinction of the dinosaurs

Woodward handles these situations through counterfactuals: if (perhaps contrary to fact) the manipulation of the factors are possible, then there is a way to alter the phenomena in question.

That is, one must be able to associate with any successful explanation a **hypothetical or counterfactual experiment**.

### Structure of Causal Relationships

Variables are the relata of causal relationships

- Variables (X, Y, Z) represent the properties
- Values represent the different states that properties can take

The explanans must have associated hypothetical experiments that show how their manipulation would be a way of altering the explanandum.

Robert Koch

- Studied whether certain bacteria caused diseases with animal inoculation's
- When studying Cholera, he was unable to inoculate animals and for ethical reasons could not experiment on humans
    - Koch turns to "natural experiments"
    - A person in a village has Cholera and washes their clothes in the community water supply, after which a Cholera outbreak occurs

The experiments for causal relationships have to be "surgical" or "ideal" interventions. That is an intervention that changes only a single variable.

## Other Accounts

The interventionist account is the current modern standard, but there were 2 major earlier accounts of causation

1. Regularity theory of causation (Hume)
2. Connected process account of causation (Salmon)

### Regularity Theory

Hume claims that causation is *constant conjunction*. That is effects regularly follow from their causes. This suffers from a major issue

\begin{center}
    Correlation does not equal causation
\end{center}

Correlation under this sense of regularity would be falsely identified as causality. For example, a storm occurring and a barometer changing it's reading are correlated, but the storm doesn't cause a change in the reading and vice versa. But since they occur regularly, they would be considered causally related under this theory.

### Connected Process Account

Salmon describes this account as having 2 main features

1. There's a physical connection between the cause and effect
2. The cause transmits some "mark" to its effects

That is, X is a cause of Y only when
- X is spatio-temporally connected to Y
- X transmits a mark or structure to Y
    - Mark can be momentum, energy, electric charge, etc.

There are 3 major problems with this account

1. Absence causation
    - There are many causal relationships where the absence of something leads to the effect (ex. Scurvy, missing an alarm, forgetting to do something, lack of resources or policies, etc.)
    - This cannot be captured as there is no physical thing you can associate with the absence of something
2. Causal experiments in science
    - Koch discovered that intervening on a bacteria caused a bacteria. However he never showed what the physical process was that connected them
3. Some connected processes don't seem causal
    - There can be many things that seem physically connected to outcomes of interest but are not causal
    - Touching a "magic" stone in the morning causes someone to do good at their job
4. Problems for the social sciences
    - It is hard to determine the physical processes behind social behavior that has causal relationships

## Normativity of Causality

The focus on the previous accounts has been about being descriptive. The question is if these accounts can help clarify causation in science. For the interventionist account, can it help scientists. Consider the following causal relationship

\begin{center}
    One of the causes of lung cancer is having lungs
\end{center}

This statement would be hard to argue as misleading or incorrect without some conceptualization of causality. Using the interventionist account, it is clear that controlling the presence of lungs just controls if the patient is alive or dead. It doesn't effect if the patient will develop lung cancer. That is why lungs are included in the background conditions when asking questions about lung cancer. We are interested in the causes of lung cancer in *people with lungs*.
